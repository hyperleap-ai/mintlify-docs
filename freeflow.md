So when we started building Hyperleap AI, the main thing was that businesses should be able to develop AI solutions for their own businesses across three different dominant pillars:

1. You're talking about AI chatbots that are customer-facing  
2. AI tools and assistance which are internal teams-facing  
3. AI prompts and personas which can be integrated by a REST APIs into products and workflows

There are some core tenets:

* We have something called sources. Each source can hold a bunch of documents, web pages, or text snippets.  
* Any prompt (any AI experience) can be attached to a source or multiple sources.

When it comes to chatbots, that is our main offering. In chatbots, what happens is people can create behavior (set the behavior of the chatbot \- what exactly the chatbot should be doing), then attach the chatbot to a bunch of sources which will provide information in a grounded way. The branding is also set. In a way, you design the chatbot like you can clearly say these are all the different elements \- let's say the headers should look like this, there is a background image, this and that. The textbox should look like this, the fonts should look like that, all this. So the branding can be absolutely inline with the web page that way the chatbot just flows into the web page. In fact nobody will even realize it's a third party chatbot that they are chatting with. But it's way more than just a simple AI chatbot. We also integrate over the social channels, so the same chatbot you can sort of integrate with your Facebook page or Instagram business profile/business handle or WhatsApp number. And then whenever somebody messages you on that number, the AI responds instead of the person responding. And then you can come back here and also say that you want to pause auto-responses, and then you can reply by yourself as well. Other than that, there are even more features as part of chatbots. The primary one being that you can capture the leads \- you don't need to directly start chatting. You can enable a lead form that allows people to submit their details before even the chat begins.

There is a feature called Assets. In Assets, what you do is you upload photos, documents, and web links and they are presented as is. You usually have a description along with it. The AI intelligently figures out that "oh, the user is asking to check out a gallery of photos" and it presents the gallery of photos within the chatbot for them to see or maybe they want to download a document like a floor plan and AI will help with that directly giving a link to that floor plan.

Other than Assets, we also have options to say "is the chatbot visible only on desktop or mobile, or is it displayed on both places". We also send a conversation transcript X minutes after the chat has started and that is another thing. And also a bunch of other options like this. What happens is even as the conversations are happening (when people chat), their phone number or email address is captured right, so that is displayed as a lead list essentially, and from there you can see the exact conversation what the user made. And obviously you can keep course correcting the prompt as well as the source documents to make sure they are 100% accurate and in line with what you are expecting to reply to the user.   
Hey, when it comes to brandability, you also have to think that you can customize:

* The colors of the headers  
* The fonts  
* You can even upload a logo as part of the header  
* You can even upload different user avatars or system messages (like the assistant avatars)  
* You can set what is the first message that you want to show in the chatbot  
* All this kind of stuff also exists as content you can set whatever content you want wherever it is configurable

Then you have a chat button \- how it should look like, what is a message beside it? All these things are customizable.   
To add, what we do is when you are setting up your chatbot, we have a very simple import behavior. So you can import a set of preset behaviors and you can basically have the system prompt dynamically composed based on the variables that you are entering or the drop-downs that you are selecting. That way you don't even need to try to sit and write the entire system prompt all by yourself. The system prompt gets dynamically built based on the kind of business you are running and the kind of products or services you are offering. There are preset behaviors as well where you load the system prompt and you just replace the bunch of variables that we ask you to with the corresponding text, and your chatbot is already ready. The main thing is that you need to upload the sources which have the documents, web links, and some text snippets. That way when they are linked to the prompts, the prompts' accuracy shoots up to close to 100% being very grounded in the truths. One thing that we are really proud of is that customers can always start with chatbots and then expand into AI tools and assistants, and later even integrate their API into prompts and personas. That way they have an end-to-end experience under one roof. Primarily we support OpenAI, but we also support Anthropic and other models in an experimental manner. The next thing that we want to talk about is the agentic nature of the chatbots. We can configure them in such a way that especially the back-end process can be automated when an incoming lead comes. Do you want to push it to a CRM? Do you want to actually alert certain teams or folks? Or do you want to go ahead and kick off a specific workflow? All this can be customized. The same agentic nature can be flown into the front-end side of things as well where the customers are interacting with chatbot. For eg., in the hospitality industry, we have use cases where the user is chatting, they are asking for an availability check of a particular property and then we have to send dates and figure out, ok, these dates, this particular property is available or not. And then you look at it and say ok, this is available, this is not available and things like that. And then maybe you want to redirect to a different property close by that also belongs to the same brand. All these things can be done as part of the hospitality industry or in general the agentic workflow that is customer-facing. Build something called a hierarchical RIG like the Retrieval Augmented Generation. Through hierarchical RIG, what we do is let's say a business of multiple products or multiple properties or multiple assets or multiple organizations under this their umbrella multiple branches it could be anything and then we are digging into specific branches to find out information. The hierarchical RIG is a two-step RAG process that will initially figure out which prope​​rty they are trying to inquire about or which branch product they are trying to inquire about and then go deeper into that specific product. This is normally tough to implement as part of RAG because there is no hierarchy in place and everything is treated equally, but in the case of hierarchical RAG, what happens is it does one level of filtration and then goes one level deeper and does filtration at that level as well. Another important thing \- I just have to double tap on this, although we already talked about it is the lead form. See, most businesses are always flying in the blind as to who are their website visitors. Again, what we are doing is if we install a chatbot without having leads in place, then we are kind of saying that ok, the same kind of opaqueness that you get as to who are the people who are visiting your website that will continue into the chatbot as well. So we highly highly recommend that people use a lead form as part of the chatbot so that they will enter their name and details and then start chatting. In fact, we even encourage them to switch on the OTP validation so that they enter the right OTP and only then they can proceed because an enormous visitor is of no use to most businesses, especially when you know they do want to follow up for sales. Let's talk also about the things that we don't actually do:

1. These are totally fully automated AI chatbots, which means there is no way for the chatbot to work in a way that there is a team sitting behind the scenes in the office that can actually respond to when the AI fails. So either the AI fails, or it doesn't deliver, there is no recourse to it. Which means they're 100% relying on AI. And the businesses that are looking at hybrid solutions where you know they want to have AI respond and then switch off and the team respond, and all this won't really work for us. We are looking at how can we completely automate the chatbots or customer service for a particular business. We are assuming that the business doesn't have the budget to hire anybody sitting behind the desk in their office trying to respond to customers. It is 100% AI responses.  
2. There is no workflow builder as in people don't have drag-drop nodes that they can connect with have connectors and say "hey this is the data flow, these are the steps A, B, C, and you know this is the end output how it should look like". There's no hard coding of these workflows of sorts. So essentially what happens is you look at chatbot builders and that node-to-node connectors and all that thing, all that is gone. We simply say "hey there is a behavior to be set just like how a GPT is done, we have a bunch of sources and now we expose a chatbot on top of it that people can straight away integrate into their website using a single line of JavaScript. And as long as they keep making the changes on the Admin side where they are configuring all this, the changes instantly get reflected on the Chatbot side of things.

Another thing is that the agentic nature of the chatbots is implemented via MCPs. So tomorrow, we have a bunch of native MCPs that we already built for ourselves. Those native MCPs are things like sending email alerts, SMS alerts, WhatsApp alerts, or fetching the booking integration or having some custom APIs built on the highest plans and things like that. But in general, what happens is all our agentic workflows are powered by MCP. So tomorrow if we want to have new API endpoints that need to be consumed either directly on the customer chatbot or in the backend workflows when the conversation is over or conversation is in progress or things like that. All of those are essentially MCP things that we will expose. Not that we really have to talk about it on the marketing side of things but this is something that will keep the entire architecture very very flexible and extensible. 

While AI chatbots or the Bot Studio is great, what our platform does is what I said it has three different modes:

1. Bot Studio  
2. AI Studio  
3. API console

In AI Studio, we have something called AI Tools and AI Assistants. AI Tools are nothing but simple forms that are backed by AI prompts, and when you execute that, you have a result that comes across, and then you can save that result or do whatever with it. AI Assistants are likewise customizable, simple system messages or complex system messages. Essentially they connect with sources behind the scenes, same like tools but these are Chattables, unlike tools which are non-Chattables. A bit of history here is that everything is backed by our v1 version of the platform. In v1, we created APIs around conversational and non-conversational AI. Conversational being AI personas and non-conversational being AI prompts, and then we exposed them as personas API and prompts API. As part of that same v1, we handled state management, memory management, audit logging, prompt management, prompt configuration versioning, and dealing with hyperparameters (e.g. top-p, temperature) so it provided a very robust backend to expose a sort of REST API that products could directly consume and build AI applications on top of. Unfortunately, what happened is that because there is a learning curve associated with it and even the market was not matured by the time we decided to not go deeper and invest all our marketing dollars in phase I.

In phase II, what we did is we started building higher-level abstractions on top of our prompts API and personas API infrastructure. The prompts API became AI tools where we had no-code forms that are behind-the-scenes they were contacting the prompts API to run it. These forms are extremely customizable \- you can say how the fields should look like, the order of the fields (whether it's a text area, text box, dropdown, etc.) and then what are the default values, min-max ranges, etc. and then ultimately all these feed into variables as part of the prompts and then the prompts execute behind-the-scenes and the result comes out of the tools and then the user can either save output or discard or use it for their day-to-day work at the workplace.

Similar to personas, we have a starting form which is also optional \- you can start chatting with any persona (sorry, I mean AI assistant) and these AI assistants behind-the-scenes they call into the personas API to make things work. In the case of AI tools or AI assistants, both can be attached with 1 or more sources so that the answers are always grounded in company knowledge.   
A little bit about v1 when you talk about Prompts API and Personas API. These are basically prompt configurations that you store and you version them. You make them say "this is a default version" and all these are going to work across model providers. So you can say "hey, one version connects to OpenAI", "the second version connects to let's say Anthropic" or something like that. And you can keep on switching the versions that way. Your core application logic never changes; you simply connect to a Prompts API with a specific version number and get things done. versioning is not there in tools and assistants, we just have a published version, and a saved version (like a draft version) for both AI tools and AI assistants. Whereas in prompts and personas, we have versioning in place, which means you can have 10 different versions doing 10 different things, 10 different prompts, 10 different models or configurations, and things like that. Also, when it comes to sources, there is no connecting to documents or connecting to webpages. It is a one-time setup where you can upload webpages, it will scrape through the content and get it, and also you can upload documents, it will scrape through the content and get it. It's not like a live connection where, as you keep updating the document, that keeps updating the sources. It is not like that. 

